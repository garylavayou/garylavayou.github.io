<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>TensorFlow - Learning Programming Book</title>
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="The example book covers examples.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../theme/pagetoc.css">
        <!-- MathJax -->
        <!-- <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
        <script async type="text/javascript" src="theme/MathJax.js"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../prefix.html">Prefix</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">程序设计语言</li><li class="chapter-item expanded "><a href="../Python/Python编程基础.html">Python</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Python/Python编程基础.html">编程基础</a></li><li class="chapter-item expanded "><a href="../Python/Python开发环境.html">开发环境</a></li><li class="chapter-item expanded "><a href="../Python/Python数据类型.html">数据类型</a></li><li class="chapter-item expanded "><a href="../Python/Python输入输出.html">输入输出</a></li><li class="chapter-item expanded "><a href="../Python/Python编程应用.html">编程应用</a></li><li class="chapter-item expanded "><a href="../Python/Python数值计算.html">数值计算</a></li><li class="chapter-item expanded "><a href="../Python/Python系统编程.html">系统编程</a></li><li class="chapter-item expanded "><a href="../Python/Python高级编程.html">高级编程</a></li></ol></li><li class="chapter-item expanded "><a href="../Java/JAVA编程基础.html">Java</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Java/JAVA编程基础.html">编程基础</a></li><li class="chapter-item expanded "><a href="../Java/Java开发环境.html">开发环境</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Java/Maven POM.html">Maven 配置</a></li></ol></li><li class="chapter-item expanded "><a href="../Java/JAVA数据类型.html">数据类型</a></li><li class="chapter-item expanded "><a href="../Java/JAVA输入输出.html">输入输出</a></li><li class="chapter-item expanded "><a href="../Java/JAVA系统编程.html">系统编程</a></li><li class="chapter-item expanded "><a href="../Java/Scala.html">Scala</a></li><li class="chapter-item expanded "><a href="../Java/ScalaFrameworks.html">Scala 框架</a></li></ol></li><li class="chapter-item expanded "><a href="../CSharp.NET/CSharp编程基础.html">C#/.NET</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../CSharp.NET/CSharp编程基础.html">编程基础</a></li><li class="chapter-item expanded "><a href="../CSharp.NET/CSharp输入输出.html">输入输出</a></li><li class="chapter-item expanded "><a href="../CSharp.NET/CSharp数据容器.html">数据容器</a></li><li class="chapter-item expanded "><a href="../CSharp.NET/CSharp数值计算.html">数值计算</a></li><li class="chapter-item expanded "><a href="../CSharp.NET/dotnet开发.html">.NET 开发</a></li></ol></li><li class="chapter-item expanded "><a href="../CC++/Modern C++.html">C and C++</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../CC++/Modern C++.html">Modern C++</a></li><li class="chapter-item expanded "><a href="../CC++/C++开发环境.html">开发环境</a></li><li class="chapter-item expanded "><a href="../CC++/C++容器.html">数据容器</a></li><li class="chapter-item expanded "><a href="../CC++/输入输出.html">输入输出</a></li><li class="chapter-item expanded "><a href="../CC++/标准函数库.html">标准库</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../CC++/数学函数.html">数学函数</a></li></ol></li></ol></li><li class="chapter-item expanded "><div>Web开发</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="../JavaScript/JavaScript.html">JavaScript</a></li><li class="chapter-item expanded "><a href="../JavaScript/TypeScript.html">TypeScript</a></li><li class="chapter-item expanded "><a href="../JavaScript/JS开发环境.html">开发环境</a></li></ol></li><li class="chapter-item expanded "><div>开发工具</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="../开发环境/git.html">Git</a></li><li class="chapter-item expanded "><a href="../笔记/正则表达式.html">正则表达式</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><li class="part-title">操作系统</li><li class="chapter-item expanded "><a href="../Linux/Linux配置和管理.html">Linux</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Linux/Linux配置和管理.html">配置管理</a></li><li class="chapter-item expanded "><a href="../Linux/Linux-Shell.html">Shell Script</a></li><li class="chapter-item expanded "><a href="../Linux/Linux发行版.html">Linux 发行版</a></li><li class="chapter-item expanded "><a href="../Linux/操作系统原理.html">操作系统原理</a></li></ol></li><li class="chapter-item expanded "><a href="../Windows/Windows配置管理.html">Windows</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Windows/Windows配置管理.html">配置管理</a></li><li class="chapter-item expanded "><a href="../Windows/Windows Shell.html">Shell</a></li><li class="chapter-item expanded "><a href="../Windows/Windows Applications.html">应用软件</a></li></ol></li><li class="chapter-item expanded "><div>应用软件</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="../应用软件/程序开发软件.html">程序开发</a></li><li class="chapter-item expanded "><a href="../应用软件/服务器管理软件.html">服务器管理</a></li><li class="chapter-item expanded "><a href="../应用软件/网络访问软件.html">网络访问</a></li><li class="chapter-item expanded "><a href="../应用软件/网络服务软件.html">网络服务</a></li><li class="chapter-item expanded "><a href="../应用软件/文档生成软件.html">文档生成</a></li><li class="chapter-item expanded "><a href="../应用软件/文件处理软件.html">文件处理</a></li><li class="chapter-item expanded "><a href="../应用软件/协作办公软件.html">协作办公</a></li><li class="chapter-item expanded "><a href="../应用软件/知识管理软件.html">知识管理</a></li><li class="chapter-item expanded "><a href="../应用软件/多媒体编辑软件.html">多媒体编辑</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><li class="part-title">机器学习</li><li class="chapter-item expanded "><a href="../机器学习/机器学习实践.html">机器学习实践</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../机器学习/ScikitLearn.html">scikit-learn</a></li><li class="chapter-item expanded "><a href="../机器学习/TensorFlow.html" class="active">TensorFlow</a></li><li class="chapter-item expanded "><a href="../机器学习/Pytorch.html">Pytorch</a></li><li class="chapter-item expanded "><a href="../机器学习/图神经网络.html">图神经网络</a></li></ol></li><li class="chapter-item expanded "><a href="../机器学习/机器学习原理与算法.html">原理与算法</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../机器学习/统计学习算法.html">统计学习算法</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><li class="part-title">数据库</li><li class="chapter-item expanded "><a href="../数据库/SQL语法.html">SQL</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../数据库/SQL DDL.html">SQL DDL</a></li><li class="chapter-item expanded "><a href="../数据库/SQL DML.html">SQL DML</a></li><li class="chapter-item expanded "><a href="../数据库/SQL数据类型.html">数据类型</a></li></ol></li><li class="chapter-item expanded "><a href="../数据库/MySQL.html">MySQL</a></li><li class="chapter-item expanded "><a href="../数据库/PostgreSQL.html">PostgreSQL</a></li><li class="chapter-item expanded "><a href="../数据库/HiveSQL.html">Hive SQL</a></li><li class="chapter-item expanded "><a href="../数据库/Elasticsearch.html">Elasticsearch</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../数据库/Elastic Datasource.html">数据源</a></li></ol></li><li class="chapter-item expanded "><a href="../数据库/Mongodb.html">Mongodb</a></li><li class="chapter-item expanded "><a href="../数据库/GraphDatabase.html">图数据库</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">服务和大数据平台</li><li class="chapter-item expanded "><a href="../服务器/分布式大数据处理.html">分布式大数据处理</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../服务器/CDH6大数据集群离线安装.html">CDH6 安装教程</a></li><li class="chapter-item expanded "><a href="../服务器/Spark Python API.html">Pyspark</a></li><li class="chapter-item expanded "><a href="../服务器/流数据处理.html">流数据处理</a></li></ol></li><li class="chapter-item expanded "><a href="../服务器/容器编排.html">容器编排</a></li><li class="chapter-item expanded "><a href="../服务器/虚拟化.html">虚拟化</a></li><li class="chapter-item expanded "><div>任务编排</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="../服务器/Airflow.html">Airflow</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><li class="part-title">其他</li><li class="chapter-item expanded "><div>数据标记语言</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="../数据交换语言/JSON and YAML.html">JSON and YAML</a></li><li class="chapter-item expanded "><a href="../数据交换语言/XML.html">XML</a></li><li class="chapter-item expanded "><a href="../数据交换语言/HTML.html">HTML</a></li></ol></li><li class="chapter-item expanded "><div>网络协议</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="../Protocols/http.html">HTTP</a></li><li class="chapter-item expanded "><a href="../Protocols/DNS.html">DNS</a></li><li class="chapter-item expanded "><a href="../Protocols/端口分配.html">端口分配</a></li><li class="chapter-item expanded "><a href="../Protocols/IP protocol numbers.html">IP 承载协议</a></li><li class="chapter-item expanded "><a href="../Protocols/RPC.html">RPC</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Learning Programming Book</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <!-- Page table of contents -->
                        <div class="sidetoc"><nav class="pagetoc"></nav></div>

                        <h1 id="tensorflow"><a class="header" href="#tensorflow">TensorFlow</a></h1>
<p><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5.html#%E5%AE%89%E8%A3%85TensorFlow">安装TensorFlow</a>。</p>
<h2 id="数据结构"><a class="header" href="#数据结构">数据结构</a></h2>
<h3 id="tensor"><a class="header" href="#tensor">Tensor</a></h3>
<p>操作间传递的数据的数据结构都是<code>Tensor</code>，内部可以看作储存了一个N维的数组（类似于<code>Numpy.ndarray</code>）。 <a href="http://www.tensorfly.cn/tfdoc/resources/dims_types.html">Rank, Shape, 和 Type.</a></p>
<pre><code class="language-python">x.name         # 'input:0'
x.valaue_index # 0
x.op.name      # 'input'
</code></pre>
<h5 id="创建变量"><a class="header" href="#创建变量">创建变量</a></h5>
<p>当训练模型时，用变量来<strong>存储和更新参数</strong>。变量的初始值可以为Numpy数组或tensorflow提供的初始化方法（<code>tf.zeros</code>、<code>tf.random_normal</code>等）生成。</p>
<pre><code class="language-python">state = tf.Variable(0, name=&quot;counter&quot;)
biases = tf.Variable(tf.zeros([200]), name=&quot;biases&quot;, dtype=tf.int32)
weights = tf.Variable(tf.random_normal([784, 200], stddev=0.35),name=&quot;weights&quot;)
</code></pre>
<p><code>tf.Variable</code>操作储存初始值以及相关信息（例如<code>name</code>）。变量类型至关重要，不同类型的变量无法进行运算。</p>
<h4 id="常量"><a class="header" href="#常量">常量</a></h4>
<pre><code class="language-python">one = tf.constant(1)
</code></pre>
<h3 id="计算图"><a class="header" href="#计算图">计算图</a></h3>
<p>TensorFlow将耗时计算任务完全运行在Python外部，通过计算图来描述各计算任务（Operation）间的交互。因此Python代码的目的是用来构建这个可以在外部运行的计算图，以及安排计算图的哪一部分应该被运行。</p>
<p>变量的初始化必须在模型的其它操作运行之前先明确地完成。</p>
<pre><code class="language-python"># 在计算图启动之后，变量必须先经过`初始化` 操作初始化
# 事先定义初始化操作：
init_op = tf.initialize_all_variables()
with tf.Session() as sess:
    sess.run(init_op)  # Run the init operation.
    # Use the model
</code></pre>
<p><code>tf.initialize_all_variables()</code>函数便捷地添加一个操作来初始化模型的所有变量。你也可以给它传入一组变量进行初始化。(事实上是一个<code>tf.assign</code>操作)</p>
<p>有时候会需要用另一个变量的初始化值给当前变量初始化，而<code>tf.initialize_all_variables()</code>是并行地初始化所有变量，所以在有这种需求的情况下需要小心。用其它变量的值初始化一个新的变量时，使用其它变量的<code>initialized_value()</code>属性。</p>
<h4 id="激活函数"><a class="header" href="#激活函数">激活函数</a></h4>
<p>内置激活函数定义在<code>tensorflow.keras.activations</code>模块中，可使用激活函数的函数名或函数对象作为<code>activation</code>参数的值。函数名会由<code>tensorflow.keras.activations.deserialize()</code>方法（或<code>get()</code>）转换为函数对象。</p>
<h2 id="session"><a class="header" href="#session">Session</a></h2>
<p>Tensorflow依赖于一个高效的C++后端来进行计算。与后端的这个连接叫做session。一般而言，使用TensorFlow程序的流程是先创建一个图，然后在session中启动它。</p>
<pre><code class="language-python">import tensorflow as tf
sess = tf.Session()
result = sess.run(graph)
sess.close()

with tf.Session() as sess:
    [with tf.device(&quot;/gpu:1&quot;):]
        result = sess.run(result)
</code></pre>
<h3 id="管理多个图"><a class="header" href="#管理多个图">管理多个图</a></h3>
<h3 id="取回结果"><a class="header" href="#取回结果">取回结果</a></h3>
<p>可以在使用<code>Session</code>对象的<code>run()</code>调用 执行图时, 传入一些 tensor, 这些 tensor 会帮助你取回结果。</p>
<h3 id="feed"><a class="header" href="#feed">Feed</a></h3>
<pre><code class="language-python">input1 = tf.placeholder(tf.types.float32)
input2 = tf.placeholder(tf.types.float32)
output = tf.mul(input1, input2)
with tf.Session() as sess:
  print sess.run([output], feed_dict={input1:[7.], input2:[2.]})
</code></pre>
<h3 id="interactivesession"><a class="header" href="#interactivesession">InteractiveSession</a></h3>
<p><code>InteractiveSession</code>让你在运行图的时候，插入一些计算图，这些计算图是由某些操作(operations)构成的。</p>
<p>如果你没有使用<code>InteractiveSession</code>，那么你需要在启动session之前构建整个计算图，然后启动该计算图。</p>
<pre><code class="language-python">import tensorflow as tf
sess = tf.InteractiveSession()
x = tf.Variable([1.0, 2.0])
a = tf.constant([3.0, 3.0])
x.initializer.run()
sub = tf.sub(x, a)
</code></pre>
<h3 id="使用gpu计算"><a class="header" href="#使用gpu计算">使用GPU计算</a></h3>
<p><a href="https://www.tensorflow.org/guide/gpu?hl=zh-cn">使用 GPU  | TensorFlow Core</a></p>
<pre><code class="language-python">devs = tf.config.list_physical_devices()  # 列出计算设备，包括CPU、GPU
with tf.device(devs[0].name.replace('physical_device:','')):
   # 构建计算图
</code></pre>
<p>设备名称形如<code>'/physical_device:CPU:0'</code>，而<code>tf.device</code>只需要<code>'/CPU:0' </code>。 </p>
<h2 id="构建模型"><a class="header" href="#构建模型">构建模型</a></h2>
<h3 id="权重初始化"><a class="header" href="#权重初始化">权重初始化</a></h3>
<blockquote>
<p><em>Weight initialization is a procedure to set the weights of a neural network to small random values that define the starting point for the optimization (learning or training) of the neural network model.</em></p>
<p><em>We cannot initialize all weights to the value 0.0 as the optimization algorithm results in some asymmetry in the error gradient to begin searching effectively.</em></p>
<p><a href="https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/">Weight Initialization for Deep Learning Neural Networks (machinelearningmastery.com)</a></p>
</blockquote>
<h3 id="训练"><a class="header" href="#训练">训练</a></h3>
<blockquote>
<p><em>We run a machine learning “algorithm” on a dataset to get a machine learning “model.”</em></p>
<ul>
<li><strong>Algorithm</strong>: Procedure run on data that results in a model (e.g. training or learning).</li>
<li><strong>Model</strong>: Data structure and coefficients used to make predictions on data.</li>
</ul>
<p><em>Stochastic machine learning algorithms use randomness during learning, ensuring a different model is trained each run.</em></p>
<ul>
<li>Initialization, such as weights.</li>
<li>Regularization, such as dropout.</li>
<li>Layers, such as word embedding.</li>
<li>Optimization, such as stochastic optimization.</li>
</ul>
<p><a href="https://machinelearningmastery.com/different-results-each-time-in-machine-learning/">Why Do I Get Different Results Each Time in Machine Learning? (machinelearningmastery.com)</a></p>
<p><em>The random initialization allows the network to learn a good approximation for the function being learned. Nevertheless, there are times when you need the exact same result every time the same network is trained on the same data. Such as for a tutorial, or perhaps operationally.</em></p>
<h5 id="seed-the-random-number-generator"><a class="header" href="#seed-the-random-number-generator">Seed the Random Number Generator</a></h5>
<p><em>Random number generators require a seed to kick off the process, and it is common to use the current time in milliseconds as the default in most implementations.</em></p>
</blockquote>
<pre><code class="language-python">from numpy.random import seed
seed(1)
from tensorflow import set_random_seed
set_random_seed(2)
</code></pre>
<blockquote>
<p><em>This is a best practice because it is possible that some randomness is used when various Keras or Theano (or other) libraries are imported as part of their initialization, even before they are directly used.</em></p>
</blockquote>
<h2 id="keras"><a class="header" href="#keras">Keras</a></h2>
<p>Keras库结构：</p>
<ul>
<li>
<p>models：包括神经网络模型的定义，例如<code>Sequential</code>。</p>
<pre><code class="language-python">from keras.models import Sequential
</code></pre>
</li>
<li>
<p>layers：神经网络各层的模型定义，例如<code>Dense</code>。</p>
<pre><code class="language-python">from keras.layers import Dense
model.layers # 获取模型中各层对象。
</code></pre>
</li>
</ul>
<h3 id="模型类"><a class="header" href="#模型类">模型类</a></h3>
<h4 id="sequential"><a class="header" href="#sequential">Sequential</a></h4>
<h3 id="层类"><a class="header" href="#层类">层类</a></h3>
<h4 id="输入"><a class="header" href="#输入">输入</a></h4>
<p><code>Input</code>类：限定模型的输入维度。</p>
<pre><code class="language-python">input=Input(shape=, batch_shape=, name=, dtype=, sparse=, tensor=)
</code></pre>
<p>当模型仅包含输入层时，模型不包含任何可训练参数（权重矩阵和偏置）；训练参数位于两层之间。使用<code>model.summary()</code>可查看层定义、输出维数以及参数数量，使用<code>model.inputs</code>, <code>model.outputs</code>查看整个模型的输入输出维数。</p>
<h4 id="预处理"><a class="header" href="#预处理">预处理</a></h4>
<p><a href="https://www.tensorflow.org/guide/keras/preprocessing_layers">Working with preprocessing layers  | TensorFlow Core</a></p>
<h5 id="normalization"><a class="header" href="#normalization">Normalization</a></h5>
<h4 id="dense"><a class="header" href="#dense">Dense</a></h4>
<pre><code class="language-python">layer = Dense(
    units,                     # 计算单元数量（输出数量）
    activation=None,           # 激活函数,不指定则直接输出
    use_bias=True,             # 是否添加偏置
    bias_initializer=&quot;zeros&quot;,  # 偏置向量初始化函数
    kernel_initializer=&quot;glorot_uniform&quot;, # 权重矩阵初始化方法
    **kwargs
)
</code></pre>
<p>其他参数<code>kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint</code>。</p>
<p>模型参数数量：<code>(num_input+1)*units</code>，每个计算单元对应一组权重和一个偏置：$\mathbf{y}=\mathbf{Wx}+\mathbf{b}$；</p>
<h4 id="conv2d"><a class="header" href="#conv2d"><a href="https://keras.io/api/layers/convolution_layers/convolution2d/">Conv2D</a></a></h4>
<p><a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8E%9F%E7%90%86%E4%B8%8E%E7%AE%97%E6%B3%95.html#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN">2D卷积层</a>：创建卷积核与输入数据进行运算（$\mathbf{y}=\mathbf{wx}+b$）。</p>
<pre><code class="language-python">layer = Conv2D(
   filters,         # 每个输入通道的卷积核数量（对应输出图像的数量）
   kernel_size,     # 卷积核大小
   strides=(1, 1),  # 卷积滑动的步长
   padding='valid', # 边缘填充，&quot;valid&quot;不填充，&quot;same&quot;填充0
   data_format=&quot;channels_last&quot;, 
   input_shape=(28,28,3),               # 28*28 RGB image
   activation=None, use_bias=True, bias_initializer='zeros',            
   kernel_initializer='glorot_uniform', # 卷积核(权重矩阵)初始化函数
   **kwargs) -&gt; None
</code></pre>
<p><code>data_format</code>：输入数据格式，数据中RGB通道的表示方式：<code>channels_last-&gt;(batch_size, height, width, channels)</code>；<code>channels_first-&gt;(batch_size, channels, height, width)</code>；</p>
<p><code>input_shape</code>：当作为输入层时，使用此参数指定输入数据样本的维数（对应<code>data_format</code>去掉<code>batch_size</code>）。</p>
<blockquote>
<p>其他参数：<code>dilation_rate, groups,</code></p>
</blockquote>
<p>输出维数：</p>
<ul>
<li><code>channels_last-&gt;(batch_size, new_rows, new_cols, filters)</code>；</li>
<li><code>channels_first-&gt;(batch_size, filters, new_rows, new_cols)</code>；</li>
</ul>
<h4 id="maxpooling2d"><a class="header" href="#maxpooling2d">MaxPooling2D</a></h4>
<h4 id="upsampling2d"><a class="header" href="#upsampling2d">UpSampling2D</a></h4>
<h3 id="构建编译模型"><a class="header" href="#构建编译模型">构建编译模型</a></h3>
<h5 id="构建模型-1"><a class="header" href="#构建模型-1">构建模型</a></h5>
<p><strong>顺序式</strong>构建：创建<code>Sequential</code>对象，并使用<code>model.add(layer)</code>方法逐次添加层。</p>
<pre><code class="language-python">from tf.keras import Input,Model
from tf.keras.layers import Dense
model = tf.keras.Sequential()
model.add(Dense(8, input_shape=(16,))) 
model.add(Dense(4))                    # automatic shape inference
</code></pre>
<blockquote>
<p><code>input_shape</code>参数用于限定模型的输入数据维数，等效于首先添加<code>Input(shape=(16,))</code>；如果未指定输入维数，则会在训练时根据输入维数确定输入层到第一层的权重矩阵维数。</p>
</blockquote>
<p><strong>函数式API</strong>：将每层对象视为函数，将前一层的输出作为该层的输入；最后使用输入和最后的输出构建模型，通过输入输出关系构建整个网络。</p>
<pre><code class="language-python">inputs = Input(shape=(3,))
x = Dense(4, activation=tf.nn.relu)(inputs)     
outputs = Dense(5, activation=tf.nn.softmax)(x)
model = Model(inputs=inputs, outputs=outputs)  
</code></pre>
<h5 id="配置keras模型"><a class="header" href="#配置keras模型"><a href="https://keras.io/api/models/model_training_apis/">配置Keras模型</a></a></h5>
<pre><code class="language-python">model.compile(
    optimizer=&quot;rmsprop&quot;,   # 优化算法
    loss=None,             # 损失函数
    metrics=None,          # 性能度量函数，如accuracy,mse
    loss_weights=None,
    weighted_metrics=None,
    **kwargs
)
</code></pre>
<blockquote>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers">优化算法：<code>&quot;sgd&quot;, &quot;adam&quot;, ...</code></a>；</p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses">损失函数</a>；</p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics">性能度量函数</a>；</p>
</blockquote>
<h5 id="训练模型"><a class="header" href="#训练模型">训练模型</a></h5>
<pre><code class="language-python">fit()
</code></pre>
<blockquote>
<p><a href="https://keras.io/api/callbacks/model_checkpoint/"><code>ModelCheckpoint</code></a> callback is used in conjunction with training using <code>model.fit()</code> to save a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved.</p>
</blockquote>
<h3 id="自定义模型组件"><a class="header" href="#自定义模型组件">自定义模型组件</a></h3>
<h4 id="自定义模型"><a class="header" href="#自定义模型">自定义模型</a></h4>
<pre><code class="language-python">class CustomModel(keras.Model):
  def get_config(self):
    return {&quot;hidden_units&quot;: self.hidden_units}
  @classmethod
  def from_config(cls, config):
    return cls(**config)
</code></pre>
<p><strong>自定义模型的导入导出</strong>：需要定义<code>get_config()</code>方法用于导出自定义类型的参数，<code>from_config</code>用于正确初始化模型和层对象。</p>
<h4 id="自定义层"><a class="header" href="#自定义层">自定义层</a></h4>
<pre><code class="language-python">class CustomLayer(keras.Layer):
  pass
</code></pre>
<p><a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models">Making new Layers and Models via subclassing  | TensorFlow Core</a></p>
<h3 id="常见问题"><a class="header" href="#常见问题">常见问题</a></h3>
<ol>
<li><a href="https://stackoverflow.com/questions/40785224/tensorflow-cannot-interpret-feed-dict-key-as-tensor">neural network - Tensorflow: Cannot interpret feed_dict key as Tensor - Stack Overflow</a></li>
</ol>
<h2 id="序列化数据和模型"><a class="header" href="#序列化数据和模型">序列化数据和模型</a></h2>
<h3 id="保存tensorflow模型"><a class="header" href="#保存tensorflow模型">保存TensorFlow模型</a></h3>
<h5 id="protocol-buffers"><a class="header" href="#protocol-buffers">Protocol Buffers</a></h5>
<p><a href="https://developers.google.com/protocol-buffers/docs/pythontutorial">Why Use Protocol Buffers?</a></p>
<h4 id="保存和加载计算图"><a class="header" href="#保存和加载计算图">保存和加载计算图</a></h4>
<p>The <code>GraphDef</code> class is an object created by the <em>ProtoBuf</em> library. After you've created a TensorFlow <code>Graph</code> object, you can save it out by calling <code>as_graph_def()</code>, which returns a <code>GraphDef</code> object.</p>
<p>保存<code>GraphDef</code>。</p>
<pre><code class="language-python">tf.io.write_graph(
    graph_or_graph_def, # A Graph or a GraphDef protocol buffer.
    logdir, # Directory where to write the graph
    name,	# file name
    as_text=True # By default, writes as an ASCII proto
)
</code></pre>
<h5 id="text-and-binary-formats"><a class="header" href="#text-and-binary-formats">Text and Binary Formats</a></h5>
<p>Text Format is a human-readable form, which makes it nice for debugging and editing, but can get large when there's numerical data like weights stored in it.</p>
<p>Binary format files are a lot smaller than their text equivalents, even though they're not as readable.</p>
<pre><code class="language-python">f.write(graph_def.SerializeToString())  # save as binary
graph_def.ParseFromString(f.read())     # read from binary
</code></pre>
<h4 id="保存和加载变量"><a class="header" href="#保存和加载变量">保存和加载变量</a></h4>
<h5 id="保存变量"><a class="header" href="#保存变量">保存变量</a></h5>
<pre><code class="language-python">saver = tf.train.Saver()
with tf.Session() as sess:
  sess.run(init_op)
  # Do some work with the model.
  # Save the variables to disk.
  save_path = saver.save(sess, &quot;/tmp/model.ckpt&quot;)
  print(&quot;Model saved in path: %s&quot; % save_path)
</code></pre>
<p>默认保存全部变量。在创建Saver对象时指定要保存的变量，可以创建多个Saver对象以保存不同分组的变量。</p>
<pre><code class="language-python"># Add ops to save and restore only `v2` using the name &quot;v2&quot;
saver = tf.train.Saver({&quot;v2&quot;: v2})
</code></pre>
<h5 id="恢复变量"><a class="header" href="#恢复变量">恢复变量</a></h5>
<p>恢复变量时无需执行初始化操作。如果只是恢复部分变量，那么需要在会话开始前初始化其他变量。</p>
<pre><code class="language-python">saver = tf.train.Saver()
# Later, launch the model
with tf.Session() as sess:
	# Restore variables from disk.
	saver.restore(sess, &quot;/tmp/model.ckpt&quot;)
    # do some work with the model
</code></pre>
<h4 id="保存和加载模型"><a class="header" href="#保存和加载模型">保存和加载模型</a></h4>
<p><code>simple_save</code>：模型（<code>*.pb</code>）和变量（<code>/variables</code>）分别输出（等效于使用<code>Saver.save</code>+<code>tf.io.write</code>）。</p>
<pre><code class="language-python">tf.saved_model.simple_save(
    session,
    export_dir,
    inputs,		// providing names for model's inputs
    outputs,	// providing names for model's outputs
    legacy_init_op=None
)
</code></pre>
<p>检查保存后的模型：</p>
<pre><code class="language-shell">saved_model_cli show --dir {export_path} --all
</code></pre>
<h5 id="serve-your-model-with-tensorflow-serving"><a class="header" href="#serve-your-model-with-tensorflow-serving">Serve your model with TensorFlow Serving</a></h5>
<p>https://www.tensorflow.org/tfx/tutorials/serving/rest_simple#serve_your_model_with_tensorflow_serving</p>
<h5 id="savedmodel"><a class="header" href="#savedmodel">SavedModel</a></h5>
<p><code>builder = tf.saved_model.builder.SavedModelBuilder(export_dir)</code></p>
<p><code>builder.add_meta_graph_and_variables</code>
<code>builder.add_meta_graph</code></p>
<p>A <strong>MetaGraph</strong> is a dataflow graph, plus its associated variables, assets, and signatures. 
A <code>MetaGraphDef </code>is the protocol buffer representation of a MetaGraph. 
A <strong>signature</strong> is the set of inputs to and outputs from a graph.</p>
<p><code>tf.saved_model.loader.load</code></p>
<p><code>Estimators</code>自动保存和恢复变量。</p>
<img src="TensorFlow.assets/1564058159981.png" alt="1564058159981" style="zoom: 67%;" />
<h4 id="export"><a class="header" href="#export">Export</a></h4>
<h5 id="freezing"><a class="header" href="#freezing">Freezing</a></h5>
<p>The <em>weights</em> usually aren't stored inside the file format during training. Instead, they're held in separate <em>checkpoint</em> files, and there are <code>Variable</code> ops in the graph that load the latest values when they're initialized.</p>
<p>==there's the <code>freeze_graph.py</code> script that takes a graph definition and a set of checkpoints and freezes them together into a single file.==</p>
<pre><code class="language-python">tensorflow.python.tools.freeze_graph.freeze_graph(...)
</code></pre>
<p><code>freeze_graph</code>调用以下方法将图中的变量（权重）转换为常量：</p>
<pre><code class="language-python">tf.graph_util.convert_variables_to_constants( 
    sess,             # Active TensorFlow session
    input_graph_def,  # GraphDef object holding the network
    output_node_names, # List of node names for the result graph.
    variable_names_whitelist=None,
    variable_names_blacklist=None
)# Warning: deprecated
</code></pre>
<blockquote>
<p>将图中的变量全部替换为常量，使得图能够以单一<code>GraphDef</code>对象被导出保存，同时也移除了关于加载和保存变量的操作。
默认转换所有变量（<code>variable_names_whitelist=None</code>）。
返回：<code>GraphDef</code>对象。</p>
</blockquote>
<h3 id="导入导出keras模型"><a class="header" href="#导入导出keras模型">导入导出Keras模型</a></h3>
<p>Keras模型包括：</p>
<ul>
<li>架构，即该模型所包含的层及其连接关系配置；</li>
<li>权重值集合，即模型的状态；</li>
<li>优化器（通过编译模型定义）；</li>
<li>损失度量指标（通过编译模型、调用<code>add_loss()</code>或<code>add_metric()</code>定义）。</li>
</ul>
<p>Keras支持将上述所有信息一次性保存（<code>SaveModel</code>或<code>H5</code>格式），或选择其中部分保存（如使用<code>JSON</code>格式保存架构）。</p>
<h5 id="导入导出完整模型数据"><a class="header" href="#导入导出完整模型数据">导入导出完整模型数据</a></h5>
<pre><code class="language-python">from tensorflow import keras
model.save(filepath,overwrite=True,include_optimizer=True,
    save_format=None,  # 'tf'(tf2.x) or 'h5'(tf1.x)
) # signatures=None, options=None, save_traces=True,
keras.models.save_model(model,...)  # --&gt; Model.save()
</code></pre>
<p><code>SaveModel</code>导出数据为一个文件夹，其中模型架构、训练配置（包括优化器、损失和度量指标）保存在<code>saved_model.pb</code>中，训练权重保存在<code>variabes/</code>目录下。相比之下，<code>H5</code>格式为单个<code>HDF5</code>文件，且不包含外部添加（<code>add_loss()</code>或<code>add_metric()</code>）的损失和度量指标（需要在加载模型时重新添加），不包含自定义类的计算图（需要在加载时通过这些对象的代码重构模型）。</p>
<p>如果某种序列化方式不能存储自定义模型或层的Python字节码，则加载时需要通过<code>custom_objects</code>参数来指定这些对象类型的名称和类名映射。如果目标平台无法导入自定义代码，则可以使用<code>pickle</code>等方法导入导出自定义类型的代码数据（不安全且存在兼容性问题）。</p>
<p><code>save_traces=True</code>[tf2.4]：在没有自定义类型的定义代码情况下也能加载模型；否则，自定义对象必须定义<code>get_config/from_config</code>方法，并在加载时通过<code>custom_objects</code>传递的类型定义进行初始化。</p>
<p>加载模型：</p>
<pre><code class="language-python">keras.models.load_model(filepath, custom_objects=None) #  compile=True, options=None 
</code></pre>
<h5 id="导入导出模型结构和权重"><a class="header" href="#导入导出模型结构和权重">导入导出模型结构和权重</a></h5>
<p>将模型架构导出为Python字典或JSON文本，其中包含了各层的类型、参数定义与连接关系。</p>
<pre><code class="language-python">config:dict = model.get_config() # the configuration of the model.
Sequential.from_config(config)   # Model.from_config(config)
</code></pre>
<pre><code class="language-python">config:str = model.to_json() # not include the weights, only the architecture.
model = keras.models.model_from_json()  # recover the model
</code></pre>
<blockquote>
<p>等效API：<code>tf.keras.models.model_to_json()</code>。</p>
<p>YAML格式：<code>model.to_yaml()  </code>和<code>keras.models.model_from_yaml()</code>。</p>
</blockquote>
<p>导入导出模型权重参数：</p>
<pre><code class="language-python">model.get_weights()  # A list of all weight tensors in the model, as Numpy arrays.
model.save_weights() # saves the weights of the model as a HDF5 file.
model.load_weights() # the architecture is expected to be unchanged.
model.set_weights()  # same shape as get_weights()
</code></pre>
<p>此外，还可以<a href="https://www.tensorflow.org/guide/keras/save_and_serialize#saving_loading_only_the_models_weights_values">调用层对象的方法</a>获取层的权重值，适用于迁移学习中权重系数迁移。</p>
<p>加载完模型架构和参数后，需要调用<code>model.compile()</code><a href="#%E9%85%8D%E7%BD%AEKeras%E6%A8%A1%E5%9E%8B">重新编译模型</a>（和最初构建时的编译配置相同）。</p>
<p><a href="https://www.tensorflow.org/guide/keras/custom_layers_and_models#saving_loading_only_the_models_weights_values">Saving &amp; loading only the model's weights values</a></p>
<h2 id="应用示例"><a class="header" href="#应用示例">应用示例</a></h2>
<h3 id="softmax模型"><a class="header" href="#softmax模型">SoftMAX模型</a></h3>
<h4 id="数据集介绍"><a class="header" href="#数据集介绍">数据集介绍</a></h4>
<p>MINST(Modified National Institute of Standards and Technology)数据集。</p>
<h5 id="训练数据集mnisttrainimages"><a class="header" href="#训练数据集mnisttrainimages">训练数据集<code>mnist.train.images</code></a></h5>
<p><code>mnist.train.images</code>是一个形状为<code>[60000, 784]</code>的张量</p>
<img src="TensorFlow.assets/mnist-train-xs.png" alt="img" style="zoom: 33%;" />
<p>每一张图片包含$28\times28$像素。</p>
<img src="TensorFlow.assets/MNIST-Matrix.png" alt="img" style="zoom: 50%;" />
<p>训练数据集标签<code>mnist.train.labels</code>是一个 <code>[60000, 10]</code> 的数字矩阵。 </p>
<img src="TensorFlow.assets/mnist-train-ys.png" alt="label" style="zoom: 33%;" />
<h4 id="softmax-regression"><a class="header" href="#softmax-regression">Softmax Regression</a></h4>
<p>给定图片代表每个数字的概率。</p>
<blockquote>
<p>为了得到一张给定图片属于某个特定数字类的证据（evidence），我们对图片像素值进行加权求和。如果这个像素具有很强的证据说明这张图片不属于该类，那么相应的权值低，相反如果这个像素拥有有利的证据支持这张图片属于这个类，对应权值高。</p>
<p>我们也需要加入一个额外的偏置量（bias），因为输入往往会带有一些无关的干扰量。</p>
</blockquote>
<p>对于给定的输入图片$\boldsymbol{x}$，它代表数字$i$的<strong>证据</strong>可以表示为</p>
<p>$$
e_i=\sum_{j}{W_{i,j}x_j+b_i}
$$</p>
<p>其中$\boldsymbol{W}_i$ 代表权重，$\boldsymbol{b}<em>i$代表数字$i$类的偏置量，$j$代表给定图片$\boldsymbol{x}$的第$j$个像素。
$$
y=\mathrm{softmax}(e_i)
$$
这里的$\mathrm{softmax}$可以看成是一个激励函数，把我们定义的线性函数的输出转换成我们想要的格式，也就是关于10个数字类的概率分布。
$$
\begin{align}
y &amp; = \mathrm{softmax}(\boldsymbol{e})=\mathrm{normalize}(\mathrm{exp}(\boldsymbol{e})) \Rightarrow\
y_i&amp;= \mathrm{softmax}(e_i)=\frac{\mathrm{exp}(e_i)}{\sum</em>{j}\mathrm{exp}(e_j)}\Rightarrow\
y&amp;=\mathrm{softmax}(\boldsymbol{W}_i\boldsymbol{x}+\boldsymbol{b})
\end{align}
$$
这个幂运算表示，更大的证据对应假设模型里面更大的乘数权重值。反之，拥有更少的证据意味着在假设模型里面拥有更小的乘数系数。将上述过程表示为图的形式：</p>
<img src="TensorFlow.assets/softmax-regression-scalargraph.png" alt="img" style="zoom: 15%;" />
<h4 id="tensorflow实现"><a class="header" href="#tensorflow实现">TensorFlow实现</a></h4>
<ol>
<li>
<p>为<strong>输入图像</strong>和<strong>目标输出类别</strong>创建节点，来开始构建计算图。</p>
<pre><code class="language-python">x = tf.placeholder(&quot;float&quot;, shape=[None, 784])
y_ = tf.placeholder(&quot;float&quot;, shape=[None, 10])
</code></pre>
</li>
<li>
<p>为模型定义权重$W$和偏置$b$。</p>
<pre><code class="language-python">W = tf.Variable(tf.zeros([784,10]))
b = tf.Variable(tf.zeros([10]))
</code></pre>
</li>
<li>
<p>初始化变量</p>
<pre><code class="language-python">sess.run(tf.initialize_all_variables())
</code></pre>
</li>
<li>
<p>回归模型计算图</p>
<p>计算每个分类的softmax概率值：</p>
<pre><code class="language-python">y = tf.nn.softmax(tf.matmul(x,W) + b)
</code></pre>
<p>为训练过程指定最小化误差用的损失函数（目标类别和预测类别之间的交叉熵）：</p>
<pre><code class="language-python">cross_entropy = -tf.reduce_sum(y_*tf.log(y))
</code></pre>
</li>
<li>
<p>训练模型</p>
<p>因为TensorFlow知道整个计算图，它可以使用自动微分法找到对于各个变量的损失的梯度值。TensorFlow有大量内置的优化算法。</p>
<pre><code class="language-python">train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)
</code></pre>
<p>往计算图上添加一个新操作，其中包括计算梯度，计算每个参数的步长变化，并且计算出新的参数值。</p>
<p>整个模型的训练可以通过反复地运行train_step来完成。</p>
<pre><code class="language-python">for i in range(1000):
  batch = mnist.train.next_batch(50)
  train_step.run(feed_dict={x: batch[0], y_: batch[1]})
</code></pre>
<p>每一步迭代，我们都会加载50个训练样本，然后执行一次train_step，并通过<code>feed_dict</code>将<code>x</code> 和 <code>y_</code>张量占位符用训练训练数据替代。</p>
</li>
<li>
<p>评估模型</p>
<pre><code class="language-python">correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))
</code></pre>
</li>
</ol>
<h3 id="多层卷积网络"><a class="header" href="#多层卷积网络">多层卷积网络</a></h3>
<h4 id="深入mnist"><a class="header" href="#深入mnist">深入MNIST</a></h4>
<p><strong>权重初始化</strong>：加入少量的噪声来打破对称性以及避免0梯度。</p>
<p>偏置初始化：由于我们使用的是ReLU神经元，因此比较好的做法是用一个较小的正数来初始化偏置项，以避免神经元节点输出恒为0的问题（dead neurons）。</p>
<pre><code class="language-python">def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../机器学习/ScikitLearn.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                            <a rel="next" href="../机器学习/Pytorch.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../机器学习/ScikitLearn.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                    <a rel="next" href="../机器学习/Pytorch.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript" src="../theme/pagetoc.js"></script>
        <script type="text/javascript" src="../theme/MathJax.js"></script>
    </body>
</html>